## サンドボックス
### 従来のサンドボックス実装方法
従来の方法では、サンドボックス用のディメンション（例えば「sandboxes」という名前）を追加し、ユーザーごとにメンバー（SB1、SB2など）を割り当てます。そして、計算スクリプトを使ってベースとなるデータを各ユーザーのメンバーにコピーします。

* 問題点: この方法では、サンドボックスを作成するたびに、事実上データベース全体が複製（クローン）されます。
    * ブロック数が増加します。
    * ユーザーが増えるほどキューブが肥大化し、バックアップ時間、ライフサイクル操作、再構築などが長くなります。

### 新しい軽量サンドボックス機能
Essbase21cで利用可能な新しいシナリオ管理機能（軽量サンドボックス）は、この問題を解決します。

* 仕組み: この機能を有効にすると、ユーザーはベースデータをコピーすることなく、プライバシーと分離が確保された自身のサンドボックスで作業できます。変更が加えられたデータのみが、新しいブロックとして追加で保存されます。

#### メリット
* ブロック数の最小化
    * サンドボックス機能を有効にしただけでは、データベースのブロック数は増加しません。例えば、354ブロックのデータベースで機能を有効にしても、ブロック数は354のままでした。
    * ユーザーがサンドボックス内の1つのブロック（データセル）の値を変更すると、データベース全体では1ブロックのみが追加されます。例えば、354ブロックだったデータベースは355ブロックになりました。
    * すでに変更が加えられたブロック内の別の値を変更しても、新たなブロックは追加されません。
* 各ユーザーは、キューブを肥大化させることなく、プライバシーと分離の恩恵を受けられます。これにより、何千人ものユーザーがそれぞれ独自のサンドボックスを持つことが可能になります。

### 結論
* Essbase21cの軽量サンドボックス機能は、変更されたデータに対応するブロックのみを追加するため、データベースが使用するブロック数を最小限に抑えることができます。

## キューブの最適化
1. はじめに：Essbase 21cの新機能「Optimize Cube」ユーティリティ
    1. 「Optimize Cube」の概要と目的
        * ハイブリッドBSOキューブのパフォーマンス最適化ユーティリティセット
        * BSOキューブ専用（ASOは非対応）
        * Cube DesignerリボンのAdmin Tasksから利用可能
        * dbxワークブックと共に使用し、テスト用の計算・クエリシートを追加
    1. 「Optimize Cube」を構成する4つのツール
        * Baseline（ベースライン）: パフォーマンス統計をダッシュボード形式で出力・比較
        * Solve Order（解決順序）: 動的クエリの計算フローを可視化
        * Calc Cache（計算キャッシュ）: 最適な計算キャッシュサイズを特定
        * Data Distribution（データ分布）: データ分布を分析し、ブロック設計や並列計算の最適化を支援
1. 事例を用いたハイブリッドキューブの最適化
    1. ベースラインの確認と問題点の特定
        * 初期設定: すべての上位レベル疎メンバーを動的に設定
        * パフォーマンス測定: Baselineユーティリティで初期状態を測定
        * 問題の発見: クエリ時間が約10分（594秒）と非常に遅いことを確認
            * 原因：疎ディメンション内の動的計算式（dynamic sparse formula）が、大規模な疎ディメンション（Entity）の集計前に実行されていたため
    1. テクニック1：解決順序（Solve Order）の最適化
        * 解決策の特定:
        * Solve Orderユーティリティで計算エンジン（クエリエンジン）の実行順序を可視化
        * 問題のメンバー（fbvar）の解決順序を最後に実行されるよう変更することを決定
        * 修正の実行:
            * dbxワークブック上でfbvarの解決順序を「101」に設定
            * Baselineユーティリティを再実行し、キューブを再構築
        * 結果:
            * クエリ時間が約10分から30秒へと大幅に短縮
            * 変更後の解決順序をSolve Orderダッシュボードで確認
    1. テクニック2：データ密度（Data Intensity）の最適化
        * 残存する問題: クエリ時間はまだ30秒かかっており、約50万ブロックを読み込んでいる
        * 原因：動的計算に必要なブロック数が多すぎる「データ密度」の問題
        * 解決策の特定:
            * ASOの集計ビューの考え方を応用
            * 最大規模の疎ディメンション（Entity）の上位レベルメンバーを事前に計算して格納（Store）することを決定
        * 修正の実行:
            * Entityディメンションの動的設定（X）を削除
            * CALC DIM Entityという計算スクリプトを作成し、ワークブックに追加
            * Baselineユーティリティを再実行
        * 結果:
            * クエリ時間が33秒から1秒未満へと劇的に改善
            * トレードオフとして、計算スクリプトの実行に35秒を要し、エクスポートサイズと時間が約2倍に増加
1. まとめ
    1. ハイブリッド最適化の2つの主要な問題
        * 解決順序（Solve Order）の問題
        * データ密度（Data Intensity）の問題
    1. 「Optimize Cube」ユーティリティの利点
        * 最適化プロセスの文書化に貢献
        * 設定の変更履歴を忘れずに管理できる
        * ハードウェアやソフトウェアのバージョンアップ時のパフォーマンス比較に有効
